# Stock Image CNN - PyTorch Implementation 

This is a PyTorch implementation of [**(Re-)Imag(in)ing Price Trends**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3756587)

## Announcement

This codebase is largely inherit from [Stock_CNN](https://github.com/lich99/Stock_CNN) by [@lich99](https://github.com/lich99).

Re-Implementation Authors:  Gongye Liu, Zixuan Ye, Yatian Wang, Haoqiang Guo, Zhizhou Zhong

---

## ğŸ“ˆ Experiment Results

### Training Results (Three Models Comparison)

| Model | Parameters | Best Epoch | Best Val Loss | Total Epochs |
|-------|------------|------------|---------------|--------------|
| **Baseline** | 0.71M | 18 | 0.6871 | 29 |
| **Baseline Large** | 10.23M | 26 | **0.6864** | 37 |
| **ViT** | 10.82M | 7 | 0.6917 | 18 |

### Test Results (Backtesting 2001-2019)

| Model | Test Loss | Accuracy | Selection % | Cumulative Return | Excess Return |
|-------|-----------|----------|-------------|-------------------|---------------|
| **Baseline** | 0.6942 | 51.58% | 1.85% | **19.86x** | **+16.68** |
| **Baseline Large** | 0.6926 | 52.10% | 4.47% | 17.11x | +13.93 |
| **ViT** | 0.6935 | 49.84% | 0.00% | 1.00x | -2.18 |
| Buy All (Baseline) | - | - | 100% | 3.18x | 0 |

### Key Findings

1. ğŸ† **Baseline CNN achieves the best performance** with 19.86x cumulative return over 19 years
2. ğŸ“Š **Model complexity doesn't guarantee better results** - the simplest model outperforms larger ones
3. âš ï¸ **ViT underperforms** on this task - traditional CNNs are more suitable for stock image classification
4. ğŸ’¡ **Selective stock picking works** - selecting only 1.85% of stocks yields 6x better returns than buying all

### Performance Visualization

Training Loss Comparison | Test Results Comparison
:-------------------------:|:-------------------------:
![Training](pic/training_comparison.png) | ![Test](pic/test_comparison.png)

---

## Quick Start

### ğŸ› ï¸ Installation

#### 1. Create a conda environment and install pytorch
```bash
conda create -n Math5470 python=3.10
conda activate Math5470
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu126
```

#### 2. Other dependencies
```bash
pip install -r requirements.txt
```

#### 3. Download data
Download the dataset from this [link](https://dachxiu.chicagobooth.edu/download/img_data.zip), then extract it to the `./data` directory:

```bash
cd Stock_CNN
mkdir -p data
wget https://dachxiu.chicagobooth.edu/download/img_data.zip -O data/img_data.zip
unzip data/img_data.zip -d data/
rm data/img_data.zip
```

---

### ğŸš€ Training

Run the training notebook to train all three models (Baseline, Baseline Large, ViT):

```bash
cd notebooks
jupyter notebook train.ipynb
```

Monitor the training process with TensorBoard:

```bash
tensorboard --logdir=runs
```

**Training Configuration:**
- Models: Baseline CNN, Baseline Large CNN, Vision Transformer
- Optimizer: Adam (lr=1e-5)
- Batch Size: 1024 (128 Ã— 8 GPUs)
- Early Stopping: Patience = 10 epochs

ğŸ“„ For detailed training results, see:
- [TRAINING_REPORT.md](./TRAINING_REPORT.md) (ä¸­æ–‡)
- [TRAINING_REPORT_EN.md](./TRAINING_REPORT_EN.md) (English)

---

### ğŸ“Š Testing & Backtesting

Run the test notebook to evaluate all models and perform backtesting:

```bash
cd notebooks
jupyter notebook test.ipynb
```

The test notebook will:
1. Load the best trained models from `./pt/`
2. Run inference on the test set (2001-2019, 1.4M samples)
3. Construct stock selection strategies based on model predictions
4. Compare cumulative returns across all models
5. Generate performance comparison charts in `./pic/`

ğŸ“„ For detailed test results, see:
- [TEST_REPORT.md](./TEST_REPORT.md) (ä¸­æ–‡)
- [TEST_REPORT_EN.md](./TEST_REPORT_EN.md) (English)

---

## ğŸ“ Project Structure

```
Stock_CNN/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ train.ipynb              # Training script (all 3 models)
â”‚   â””â”€â”€ test.ipynb               # Testing & backtesting script
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline.py              # Baseline CNN (0.71M params)
â”‚   â”œâ”€â”€ baseline_large.py        # Large CNN (10.23M params)
â”‚   â””â”€â”€ vit.py                   # Vision Transformer (10.82M params)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ monthly_20d/             # Stock image data
â”œâ”€â”€ pt/
â”‚   â”œâ”€â”€ baseline/best.pt         # Best Baseline model
â”‚   â”œâ”€â”€ baseline_large/best.pt   # Best Baseline Large model
â”‚   â”œâ”€â”€ vit/best.pt              # Best ViT model
â”‚   â”œâ”€â”€ training_results.json    # Training results
â”‚   â””â”€â”€ test_results.json        # Test results
â”œâ”€â”€ pic/
â”‚   â”œâ”€â”€ training_comparison.png  # Training curves comparison
â”‚   â”œâ”€â”€ test_comparison.png      # Test results comparison
â”‚   â””â”€â”€ stocks_selected.png      # Stock selection over time
â”œâ”€â”€ runs/                        # TensorBoard logs
â”œâ”€â”€ TRAINING_REPORT.md           # Training report (Chinese)
â”œâ”€â”€ TRAINING_REPORT_EN.md        # Training report (English)
â”œâ”€â”€ TEST_REPORT.md               # Test report (Chinese)
â”œâ”€â”€ TEST_REPORT_EN.md            # Test report (English)
â””â”€â”€ requirements.txt             # Python dependencies
```

---

## ğŸ“Š Model Architectures

### Baseline CNN (Recommended)
- 3-layer ConvNet with BatchNorm and LeakyReLU
- Parameters: 708,866 (0.71M)
- Best for: Production use, fast inference

### Baseline Large CNN
- Same architecture with expanded channels (96â†’192â†’384)
- Parameters: 10,233,602 (10.23M)
- Best for: When more model capacity is needed

### Vision Transformer (ViT)
- Patch-based transformer with 6 layers
- Parameters: 10,821,314 (10.82M)
- Note: Underperforms on this task

---

## ğŸ“š References

- Paper: [(Re-)Imag(in)ing Price Trends](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3756587)
- Original Implementation: [Stock_CNN by @lich99](https://github.com/lich99/Stock_CNN)

---

## ğŸ“ License

This project is for educational purposes only. Please refer to the original paper and implementation for licensing details.
